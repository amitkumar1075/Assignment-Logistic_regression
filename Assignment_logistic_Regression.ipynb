{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c99d45-170e-4128-998c-0bbf52dc4d17",
   "metadata": {},
   "source": [
    "## **Theory Questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf2064b-ce6c-4a08-8c58-59f0917915e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. What is Logistic Regression, and how does it differ from Linear Regression\n",
    "\n",
    "#ans.>> Logistic Regression is a classification algorithm used to predict discrete classes (e.g., yes/no, 0/1).\n",
    "#       Linear Regression is a regression algorithm used to predict continuous outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d18b209-da9b-422b-a1cc-ebdd53a20e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What is the mathematical equation of Logistic Regression \n",
    "\n",
    "#ans.>>Logistic Regression predicts the probability \n",
    "# P(y=1∣x) = σ(z)= 1/1-(e**-z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542560a5-ab2c-411e-9cf3-054cdecdd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Why do we use the Sigmoid function in Logistic Regression \n",
    "\n",
    "#ans.>>the Sigmoid Function compresses any real-valued number into the range (0, 1), which allows us to interpret the output as a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01407818-033d-468c-9d44-071b5897b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What is the cost function of Logistic Regression \n",
    "\n",
    "#ans.>> We use Log Loss (Cross-Entropy Loss):\n",
    "# J(θ) = -(1/m) * Σ [ y(i) * log(ŷ(i)) + (1 - y(i)) * log(1 - ŷ(i)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1389e72-130d-4347-848b-77434aff77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. What is Regularization in Logistic Regression? Why is it needed \n",
    "\n",
    "#ans.>> Regularization prevents overfitting by penalizing large coefficients in the model.\n",
    "#       Needed when: Too many features or noise causes the model to fit training data too closely.\n",
    "#       Adds a penalty term to the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdea0ab-a0c8-42e2-9e33-41bc1163dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Explain the difference between Lasso, Ridge, and Elastic Net regression \n",
    "\n",
    "#ans.>>Ridge Regression: Ridge Regression adds L2 regularization (penalty on the square of coefficients)\n",
    "#          it shrinks coefficients, but doesn’t make them exactly zero.\n",
    "\n",
    "#      Lasso Regression :Lasso Regression adds L1 regularization (penalty on the absolute value of coefficients) \n",
    "#           it can shrink some coefficients to zero, effectively doing feature selection.\n",
    "\n",
    "#      Elastic Net Regression : Elastic Net Regression combines both L1 and L2 regularization, balancing between Ridge and Lasso, \n",
    "#            useful when there are many correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2a30f6-5ecc-4fc8-bbb6-5755f50e315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. When should we use Elastic Net instead of Lasso or Ridge \n",
    "\n",
    "#ans.>>Use Elastic Net when:\n",
    "#      You have many features, and some are highly correlated.\n",
    "#      You want both regularization and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c9888b-a5ba-49fc-9a58-b5f54055bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. What is the impact of the regularization parameter (λ) in Logistic Regression\n",
    "\n",
    "#ans.>> High λ: More regularization → simpler model → risk of underfitting.\n",
    "#       Low λ: Less regularization → risk of overfitting.\n",
    "#       λ is a hyperparameter and should be tuned using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa0a7924-dabf-4e39-8ad5-bbe7e562268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. What are the key assumptions of Logistic Regression\n",
    "\n",
    "#ans.>> these are the key assumptions of logistic regression :-\n",
    "#      1.Linearity between features and log-odds (not output probability).\n",
    "#      2.No multicollinearity among independent variables.\n",
    "#      3.Large sample size.\n",
    "#      4.Independence of observations.\n",
    "#      5.Features should ideally be scaled (especially with regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293660ea-6736-4f5f-8d86-7c0ff222ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. What are some alternatives to Logistic Regression for classification tasks \n",
    "\n",
    "#ans.>> these are some alternatives to Logistic Regression for classification tasks :-\n",
    "#      1.Decision Trees\n",
    "#      2.Random Forest\n",
    "#      3.Support Vector Machines (SVM)\n",
    "#      4.k-Nearest Neighbors (KNN)\n",
    "#      5.Naive Bayes\n",
    "#      6.Gradient Boosting (XGBoost, LightGBM, etc.)\n",
    "#      7.Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ee3dd5-0e11-440c-a443-24e8afd45983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. What are Classification Evaluation Metrics\n",
    "\n",
    "#ans.>>Accuracy, Precision, Recall, F1-score, ROC-AUC, Confusion Matrix, Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e1cdec-7ba1-4319-a8ea-6127ca2cba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. How does class imbalance affect Logistic Regression\n",
    "\n",
    "#ans.>> Model becomes biased toward majority class.\n",
    "#       Accuracy becomes misleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dc0f47e-5538-4a5c-88ce-16f4d8ab6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What is Hyperparameter Tuning in Logistic Regression\n",
    "\n",
    "#ans.>>It’s the process of selecting the best λ (regularization) and solver using:\n",
    "# 1.Grid Search, 2.Random Search, 3.Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4667838-feaf-42ee-9fc8-153cb8d1b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. What are different solvers in Logistic Regression?Which one should be used \n",
    "\n",
    "#ans.>> Common solvers in sklearn:\n",
    "#       1.liblinear: For small datasets, supports L1 & L2\n",
    "#       2.saga: Supports L1, L2, Elastic Net (best for large datasets)\n",
    "#       3.lbfgs: Fast, good for multiclass (default)\n",
    "#       4.newton-cg: Handles multiclass, uses Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e4bc35-65ff-40d2-86d4-f67bb5b60121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. How is Logistic Regression extended for multiclass classification \n",
    "\n",
    "#ans.>> 1.One-vs-Rest (OvR): One binary classifier per class.\n",
    "#       2.Softmax (Multinomial Logistic Regression): Directly models all classes at once using softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f78c0521-cd97-496d-81c9-de90c6486b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. What are the advantages and disadvantages of Logistic Regression \n",
    "\n",
    "#ans.>> Advantages:\n",
    "#          1.Simple, easy to implement.\n",
    "#          2.Outputs probabilities.\n",
    "#          3.Works well with linearly separable data.\n",
    "#      Disadvantages:\n",
    "#         1.Poor performance on non-linear data.\n",
    "#         2.Assumes linearity in log-odds.\n",
    "#         3.Sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c1783b-94e3-4df0-a941-0366f487c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. What are some use cases of Logistic Regression \n",
    "\n",
    "#ans.>> these are some use cases of Logistic Regression :-\n",
    "#         1.mail Spam Detection\n",
    "#         2.Customer Churn Prediction\n",
    "#         3.Credit Scoring\n",
    "#         4.Disease Prediction (e.g., diabetes, cancer)\n",
    "#         5.Marketing Campaign Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a52c08-d6b7-414f-9de0-fa094e043b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. What is the difference between Softmax Regression and Logistic Regression \n",
    "\n",
    "#ans.>>Logistic Regression is used for binary classification (only 2 classes) and uses the sigmoid function.\n",
    "#      Softmax Regression is used for multiclass classification (3 or more classes) and uses the softmax function to give probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d0706be-4958-499d-ab94-4b381c916730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification \n",
    "\n",
    "#ans.>> OvR: Trains one classifier per class; works well for unbalanced or sparse classes.\n",
    "#       Softmax: Trains one model; best for balanced, well-separated classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "670f5709-c7bf-4235-8cb9-b7b78e00d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. How do we interpret coefficients in Logistic Regression?\n",
    "\n",
    "#ans.>>Each coefficient βⱼ tells us how much the log-odds of the outcome (like success/failure, yes/no, etc.) \n",
    "#       change when xⱼ increases by 1 unit, while keeping other variables the same.\n",
    "#       If βⱼ > 0: Increasing xⱼ makes the probability of class 1 (e.g., success) go up.\n",
    "#      If βⱼ < 0: Increasing xⱼ makes the probability of class 1 go down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad006d-1d30-4de7-abbb-3f89d90aec9f",
   "metadata": {},
   "source": [
    "## **Practical Questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d1256c0-431a-4bd4-891b-26abcc86f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38b5570c-fc52-461d-a776-652523bac97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data , columns=data.feature_names)\n",
    "df[\"target\"] = data.target\n",
    "df = df[df[\"target\"] != 2]\n",
    "\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y, test_size=0.20 , random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Model Accuracy :\" , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "301fee45-8f02-40d0-b4d9-560c2d4b3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "#2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
    "model_l1 = LogisticRegression(penalty=\"l1\" , solver=\"liblinear\" , max_iter=500)\n",
    "model_l1.fit(x_train,y_train)\n",
    "y_pred_l1 = model_l1.predict(x_test)\n",
    "print(\"Model Accuracy : \", accuracy_score(y_test,y_pred_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db7f8785-e184-4373-9705-30462e24e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy :  1.0\n",
      "Coefficient : [[ 0.46100411 -0.78836575  2.18624929  0.92865666]]\n"
     ]
    }
   ],
   "source": [
    "#3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
    "model_l2= LogisticRegression(penalty=\"l2\" , solver=\"liblinear\" , max_iter=500)\n",
    "model_l2.fit(x_train,y_train)\n",
    "y_pred_l2 = model_l2.predict(x_test)\n",
    "print(\"Model Accuracy : \", accuracy_score(y_test,y_pred_l2))\n",
    "print(\"Coefficient :\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bcf7a0f-a9e6-40b1-9520-1665b8d85c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "#4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
    "model_en = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\",l1_ratio=0.2 , max_iter=500)\n",
    "model_en.fit(x_train,y_train)\n",
    "y_pred_en = model_en.predict(x_test)\n",
    "print(\"Model Accuracy : \",accuracy_score(y_test,y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80c94f7e-6dd5-4d01-a438-832f46918220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
    "model_ovr = LogisticRegression(multi_class=\"ovr\" , max_iter=500)\n",
    "model_ovr.fit(x_train,y_train)\n",
    "y_pred_ovr = model_ovr.predict(x_test)\n",
    "print(\"Model Accuracy :\",accuracy_score(y_test,y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0719f68d-d469-4d0e-a7f7-aea339079670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "Gridsearchcv Best : {'C': 1, 'penalty': 'l2'}\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\"penalty\": (\"l1\", \"l2\", \"elasticnet\"), 'C': [1, 2, 10, 20, 30, 40]}\n",
    "classifier = LogisticRegression()\n",
    "clf = GridSearchCV(classifier , param_grid= params , cv=5 ,verbose=2)\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Gridsearchcv Best :\" ,clf.best_params_)\n",
    "print(\"Accuracy :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b3a23d19-b45b-425b-b54b-eadbd766822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Avg Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model_skf = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(LogisticRegression(max_iter=500), x, y, cv=model_skf)\n",
    "print(\"Stratified K-Fold Avg Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d61ae-55d7-4208-b1a2-d93669cdc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
    "df = pd.read_csv(\"Car Sale.csv\")\n",
    "\n",
    "x = df.drop(\"Price ($)\" , axis=1)\n",
    "y = df[\"Price ($)\"]\n",
    "x_train_car , x_test_car , y_train_car , y_test_car = train_test_split(x,y, test_size=0.20,random_state=1)\n",
    "model_car = LogisticRegression(max_iter=500)\n",
    "model_car.fit(x_train_car,y_train_car)\n",
    "y_pred_car = model_car.predict(x_test_car)\n",
    "print(\"Accuracy :\",accuracy_score(y_train_car,y_pred_car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97a6b303-431b-436a-bfc5-fdbeaf7b8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV best: {'penalty': 'l2', 'C': 10}\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_clf = RandomizedSearchCV(classifier, param_distributions=params, n_iter=10, cv = 5)\n",
    "random_clf.fit(x_train,y_train)\n",
    "print(\"RandomizedSearchCV best:\", random_clf.best_params_)\n",
    "print(\"Accuracy:\", random_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67765b7e-7d47-4a6a-b2eb-fd54e91a5ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvO Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "model_ovo = OneVsOneClassifier(LogisticRegression(max_iter=500))\n",
    "model_ovo.fit(x_train, y_train)\n",
    "y_pred_ovo = model_ovo.predict(x_test)\n",
    "print(\"OvO Accuracy:\", accuracy_score(y_test,y_pred_ovo ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "031118d9-51d9-48be-b2a3-110b7d801fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAFaCAYAAAA6vGcJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsDklEQVR4nO3de1xU5do//s+aAQZEZhIUcGxQNE08pIjpxjJBzR0S6a+DppbnQ2Il6TYyt4L2U9TaZopCmIhZHtqlPtY2H8kDamqKYplapqHSVjZCbU4q4LC+fxDzNAI2a5jTWn7evtZrN2tmrXWN7tfFxXXf616CKIoiiIjI5amcHQAREVmGCZuISCaYsImIZIIJm4hIJpiwiYhkggmbiEgmmLCJiGSCCZuISCaYsImIZIIJm4hIJpiwiYga6cCBA4iJiYFer4cgCNi+fbvpvaqqKsTHx6Nr167w9vaGXq/H6NGjcfXqVcnXYcImImqk8vJydOvWDcnJyXXeu3HjBk6ePIm5c+fi5MmT2Lp1K86fP4+nnnpK8nUELv5ERGQ7giBg27ZtGDp0aIOfOX78OHr16oXLly8jKCjI4nO72SA+IiKXdOvWLVRWVlp1rCiKEATBbJ9Go4FGo2l0XMXFxRAEAffdd5+k45iwiUiRbt26BS8fP+D2DauOb9q0KcrKysz2JSQkIDExsdFxvfHGGxg5ciS0Wq2kY5mwiUiRKisrgds3oOk8DlB7SDvYWImyM+uQl5dnllQbW11XVVXh+eefR3V1NVavXi35eCZsIlI2Nw8IammJVvy9E6LVaiVXwQ2pqqrCsGHDkJubi71791p1XiZsIlI2QVWzST3GhmqT9U8//YR9+/bBz8/PqvMwYRMRNVJZWRkuXLhgep2bm4tTp07B19cXer0ezz77LE6ePIkvvvgCRqMR+fn5AABfX194eFjeruG0PiJSpJKSEuh0OmhCY6W3RIwVqMhZjeLiYotaF/v370dkZGSd/WPGjEFiYiKCg4PrPW7fvn2IiIiwOC5W2ESkbA5oiUREROButa+t6mImbCJSNkGo2aQe44KYsIlI4ayosF101Q4mbCJSNgVV2K75Y4TMfPfddxg3bhyCg4Ph6emJpk2bokePHli6dCl+/fVXu147JycH/fr1g06ngyAIWL58uc2vIQhCo+8es0ZGRgYEQYAgCNi/f3+d90VRxAMPPABBECQNDP3R6tWrkZGRIemY/fv3NxgT3dtYYbu4NWvWIDY2Fg8++CBmzZqFTp06oaqqCtnZ2UhNTcWRI0ewbds2u11//PjxKC8vx+bNm9GsWTO0adPG5tc4cuQI7r//fpuf11I+Pj5Yu3ZtnaSclZWFixcvwsfHx+pzr169Gs2bN8fYsWMtPqZHjx44cuQIOnXqZPV16Q9cYB62rTBhu7AjR45g6tSpePzxx7F9+3az22Iff/xxzJw5E7t27bJrDN9//z0mTZqEqKgou13jL3/5i93ObYnhw4fj448/xqpVq8ymcK1duxbh4eEoKSlxSBxVVVUQBAFardbpfyeKwpYIOcKiRYsgCALS0tLqXcPAw8PDbE3d6upqLF26FB07doRGo4G/vz9Gjx6NX375xey4iIgIdOnSBcePH0ffvn3RpEkTtG3bFosXL0Z1dTWA/2sX3L59GykpKabWAQAkJibWWcXsj8dcunTJtG/v3r2IiIiAn58fvLy8EBQUhGeeeQY3bvzfgjz1tUS+//57DBkyBM2aNYOnpye6d++O9evXm32mtnWwadMmzJkzB3q9HlqtFgMHDsSPP/5o2V8ygBEjRgAANm3aZNpXXFyMzz77DOPHj6/3mPnz56N3797w9fWFVqtFjx49sHbtWrPpW23atMGZM2eQlZVl+vur/Q2lNvYNGzZg5syZaNWqFTQaDS5cuFCnJVJYWAiDwYA+ffqgqqrKdP6zZ8/C29sbL774osXf9Z5UW2FL3VyQa0ZFMBqN2Lt3L8LCwmAwGCw6ZurUqYiPj8fjjz+OHTt24K233sKuXbvQp08fFBYWmn02Pz8fo0aNwgsvvIAdO3YgKioKs2fPxkcffQQAiI6OxpEjRwAAzz77LI4cOWJ6balLly4hOjoaHh4eSE9Px65du7B48WJ4e3vfdcnLH3/8EX369MGZM2ewYsUKbN26FZ06dcLYsWOxdOnSOp9/8803cfnyZXzwwQdIS0vDTz/9hJiYGBiNRovi1Gq1ePbZZ5Genm7at2nTJqhUKgwfPrzB7zZlyhR88skn2Lp1K55++mm88soreOutt0yf2bZtG9q2bYvQ0FDT39+d7avZs2fjypUrSE1Nxeeffw5/f/8612revDk2b96M48ePIz4+HkDNovjPPfccgoKCkJqaatH3vGfVVthSNxfEloiLKiwsxI0bNxq8Q+pOP/zwA9LS0hAbG4uVK1ea9oeGhqJ379549913sXDhQtP+oqIi7Ny5E7169QIADBw4EPv378fGjRsxevRotGjRAi1atAAABAQEWPUr+okTJ3Dr1i28/fbb6Natm2n/yJEj73pcYmIiKisrsW/fPtMPq8GDB+O///0v5s+fjylTpkCn05k+36lTJ9MPGgBQq9UYNmwYjh8/bnHc48ePR2RkJM6cOYPOnTsjPT0dzz33XIP963Xr1pn+u7q62nTjxHvvvYe5c+dCEASEhobCy8vrri2Odu3a4Z///OefxvfII49g4cKFiI+Px2OPPYbt27cjNzcX33zzDby9vS36jvcsBfWwXTMqkmzfvn0AUGdwq1evXggJCcGePXvM9gcGBpqSda2HHnoIly9ftllM3bt3h4eHByZPnoz169fj559/tui4vXv3YsCAAXV+sxg7dixu3LhRp9K/81FLDz30EABI+i79+vVDu3btkJ6ejtOnT+P48eMNtkNqYxw4cCB0Oh3UajXc3d0xb948FBUVoaCgwOLrPvPMMxZ/dtasWYiOjsaIESOwfv16rFy5El27drX4eJI/JmwX1bx5czRp0gS5ubkWfb6oqAgA0LJlyzrv6fV60/u16lstTKPR4ObNm1ZEW7927drhq6++gr+/P6ZNm4Z27dqhXbt2eO+99+56XFFRUYPfo/b9P7rzu9T2+6V8F0EQMG7cOHz00UdITU1Fhw4d0Ldv33o/e+zYMQwaNAhAzSyer7/+GsePH8ecOXMkX7e+73m3GMeOHYtbt24hMDCQvWtLCYIVPWzXbIkwYbsotVqNAQMG4MSJE3UGDetTm7SuXbtW572rV6+iefPmNovN09MTAFBRUWG2/84+OQD07dsXn3/+OYqLi3H06FGEh4cjLi4OmzdvbvD8fn5+DX4PADb9Ln80duxYFBYWIjU1FePGjWvwc5s3b4a7uzu++OILDBs2DH369EHPnj2tumZ9g7cNuXbtGqZNm4bu3bujqKgIf/vb36y65j1HJVi3uSAmbBc2e/ZsiKKISZMm1TtIV1VVhc8//xwA0L9/fwAw6+UCNQ/7PHfuHAYMGGCzuGpnOnz33Xdm+2tjqY9arUbv3r2xatUqAMDJkycb/OyAAQOwd+9eU4Ku9eGHH6JJkyZ2m/LWqlUrzJo1CzExMRgzZkyDnxMEAW5ublCr1aZ9N2/exIYNG+p81la/tRiNRowYMQKCIODLL79EUlISVq5cia1btzb63IqnoFkiHHR0YeHh4UhJSUFsbCzCwsIwdepUdO7cGVVVVcjJyUFaWhq6dOmCmJgYPPjgg5g8eTJWrlwJlUqFqKgoXLp0CXPnzoXBYMBrr71ms7gGDx4MX19fTJgwAQsWLICbmxsyMjKQl5dn9rnU1FTs3bsX0dHRCAoKwq1bt0wzMQYOHNjg+RMSEvDFF18gMjIS8+bNg6+vLz7++GP861//wtKlS80GHG1t8eLFf/qZ6OhoLFu2DCNHjsTkyZNRVFSEd955p96pl127dsXmzZuxZcsWtG3bFp6enlb1nRMSEnDw4EHs3r0bgYGBmDlzJrKysjBhwgSEhoZaPDh9T1LQPGwmbBc3adIk9OrVC++++y6WLFmC/Px8uLu7o0OHDhg5ciRefvll02dTUlLQrl07rF27FqtWrYJOp8MTTzyBpKQkq59wUR+tVotdu3YhLi4OL7zwAu677z5MnDgRUVFRmDhxoulz3bt3x+7du5GQkID8/Hw0bdoUXbp0wY4dO0w94Po8+OCDOHz4MN58801MmzYNN2/eREhICNatWyfpjkF76d+/P9LT07FkyRLExMSgVatWmDRpEvz9/TFhwgSzz86fPx/Xrl3DpEmTUFpaitatW5vNU7dEZmYmkpKSMHfuXLPflDIyMhAaGorhw4fj0KFDkhbCv6coaJYIH2BARIpkeoBBvwQIbp6SjhVv30JF1nyLH2DgKKywiUjZ2BIhIpIJBbVEmLCJSNlYYRMRyQQrbCIimVBQhe2aP0aIiKgOWVfY1dXVuHr1Knx8fCTd4ktErk8URZSWlkKv10OlakxtyYfwuoSrV69avFY0EclTXl5e4x4hp6CWiKwTdu1axd3f+CfUmiZOjoYcYeerjzo7BHKQ0pISPBBsaNQzNQH832p9Uo9xQbJO2LVtELWmCdw8uYj7vcCV7jojx2h0u5OzRIiIZEJBLRHX/DFCRER1sMImImVjS4SISCYU1BJhwiYiZWOFTUQkE6ywiYjkQRAE6VMDXTRhu2bdT0REdbDCJiJFU1KFzYRNRMom/L5JPcYFMWETkaKxwiYikgkmbCIimVBSwuYsESIimWDCJiJFq62wpW5SHDhwADExMdDr9RAEAdu3bzd7XxRFJCYmQq/Xw8vLCxEREThz5ozk78KETUTKJli5SVBeXo5u3bohOTm53veXLl2KZcuWITk5GcePH0dgYCAef/xxlJaWSroOe9hEpGiO6GFHRUUhKiqq3vdEUcTy5csxZ84cPP300wCA9evXIyAgABs3bsSUKVMsvg4rbCJStJqlRKS2RGqOLSkpMdsqKiokXz83Nxf5+fkYNGiQaZ9Go0G/fv1w+PBhSediwiYiRRNgRQ/7956IwWCATqczbUlJSZKvn5+fDwAICAgw2x8QEGB6z1JsiRARNSAvL8/sOaIajcbqc93ZlhFFUXKrhgmbiBStMT1srVbb6Ac/BwYGAqiptFu2bGnaX1BQUKfq/jNsiRCRsjlglsjdBAcHIzAwEJmZmaZ9lZWVyMrKQp8+fSSdixU2ESmbFRW2KPHzZWVluHDhgul1bm4uTp06BV9fXwQFBSEuLg6LFi1C+/bt0b59eyxatAhNmjTByJEjJV2HCZuIFM2alojUz2dnZyMyMtL0esaMGQCAMWPGICMjA6+//jpu3ryJ2NhY/Pbbb+jduzd2794NHx8fSddhwiYiRXNEwo6IiIAoinc9X2JiIhITEyWd907sYRMRyQQrbCJSNj7AgIhIHhzREnEUJmwiUjQmbCIimWDCJiKSCSUlbM4SISKSCVbYRKRsnCVCRCQPSmqJMGETkaIxYRMRyYSSEjYHHYmIZIIVNhEpGwcdiYjkQUktESZsIlI0JmwiIpmofWq61GNcERM2ESmakipszhIhIpIJVthEpGycJUJEJA9KaokwYRORojFhExHJhCDUbFKPcUVM2ESkaDUJW2qFbadgGomzRIiIZIIVNhEpmxUtEc4SISJyAg46EhHJBAcdiYhkQqUSoFJJy8CixM87ChM2ESkaK2xyCrUATHy0Df7a2R++3h4oKq/Ev07/B+u+vgzR2cGR3agFQK2qGQcTAVQZwX/ve5TTp/WtXr0awcHB8PT0RFhYGA4ePOjskFzWi38Jwv8Xqsc7mRcw4oPjSN73M0b1uh/P9Wzl7NDITlQC4KYCjNVApRGoFgEPtbOjkpfaQUepmytyasLesmUL4uLiMGfOHOTk5KBv376IiorClStXnBmWy+rSSosDPxXi8MVfca24Avt+LMSxS78hJNDH2aGRnbipAKNYs4kAblfX/K+b00st+ahtiUjdXJFT/9mXLVuGCRMmYOLEiQgJCcHy5cthMBiQkpLizLBc1re/FOPhNs1gaOYFAHjA3xvd7tfh8MUiJ0dG9iKgpqr+o2qxpvImyyipwnZaD7uyshInTpzAG2+8YbZ/0KBBOHz4cL3HVFRUoKKiwvS6pKTErjG6mg1H89BU44Ytkx9GdbUIlUpAalYuMs9dd3ZoZCeCAIh3JGxRhMve2OGKOA/bBgoLC2E0GhEQEGC2PyAgAPn5+fUek5SUhPnz5zsiPJc0MKQFnujsj3k7ziG38Aba+3vjtYEPoLCsEju//4+zwyNySUqaJeL0TtidP8lEUWzwp9vs2bNRXFxs2vLy8hwRost4JbItPjyah6/OXcfF6+XYdaYAm4//gtHhQc4OjexEFOsmD1dNJmR/TquwmzdvDrVaXaeaLigoqFN119JoNNBoNI4IzyV5uqsh3vH7sbFaZD9TwUTU9Kv/2Me+8zXdnZIewuu0CtvDwwNhYWHIzMw025+ZmYk+ffo4KSrXduhCEcaGt0afdr5oqdOgXwc/jOh1P7LOFzo7NLKT29W/z8MWatrWbr/Px75d7ezI5ENJs0SceuPMjBkz8OKLL6Jnz54IDw9HWloarly5gpdeesmZYbmsf2RewOS+bTBrUHs0a+KOwrJKbM+5hrVfX3Z2aGQn1WJNcq6dxieiZj42WY6DjjYyfPhwFBUVYcGCBbh27Rq6dOmCnTt3onXr1s4My2XdqDRi+Z6LWL7norNDIQcyioCRSdpqShp0dPqt6bGxsYiNjXV2GESkUEqqsJ0+S4SISO5u376Nv//97wgODoaXlxfatm2LBQsWoLratoMNTq+wiYjsyREtkSVLliA1NRXr169H586dkZ2djXHjxkGn02H69OnSTnYXTNhEpGiNaYnceTd1Q1OLjxw5giFDhiA6OhoA0KZNG2zatAnZ2dlWRl0/tkSISNmsmdL3e343GAzQ6XSmLSkpqd5LPProo9izZw/Onz8PAPj2229x6NAhDB482KZfhRU2ESlaYyrsvLw8aLVa0/6GbtyLj49HcXExOnbsCLVaDaPRiIULF2LEiBHWB14PJmwiUrTG9LC1Wq1Zwm7Ili1b8NFHH2Hjxo3o3LkzTp06hbi4OOj1eowZM8aKqOvHhE1E1EizZs3CG2+8geeffx4A0LVrV1y+fBlJSUlM2ERElnLEPOwbN25ApTIfElSr1ZzWR0QkhSOm9cXExGDhwoUICgpC586dkZOTg2XLlmH8+PHSTvQnmLCJSNEcUWGvXLkSc+fORWxsLAoKCqDX6zFlyhTMmzdP0nn+DBM2ESmaIxK2j48Pli9fjuXLl0s6TiombCJSNCUt/sQbZ4iIZIIVNhEpmpJW62PCJiJFU1JLhAmbiBSNFTYRkUwIsKLCtkskjceETUSKphIEqCRmbKmfdxTOEiEikglW2ESkaBx0JCKSCQ46EhHJhEqo2aQe44qYsIlI2QQrKmYmbCIix1NSD5uzRIiIZIIVNhEpmvD7H6nHuCImbCJSNA46EhHJBKf1ERHJhJIGHZmwiUjRuJYIERE5HCtsIlI0tkSIiGSCg45ERDLBCpuISCaUNOjIhE1EiiZA+lpOrpmuLUzYO3bssPiETz31lNXBEBFRwyxK2EOHDrXoZIIgwGg0NiYeIiKbuucGHaurq+0dBxGRXXAtESIimbjnKuw7lZeXIysrC1euXEFlZaXZe6+++qpNAiMishUXzb+SSU7YOTk5GDx4MG7cuIHy8nL4+vqisLAQTZo0gb+/PxM2EbkUJVXYktcSee211xATE4Nff/0VXl5eOHr0KC5fvoywsDC888479oiRiIhgRcI+deoUZs6cCbVaDbVajYqKChgMBixduhRvvvmmPWIkIrJa7aCj1M0VSU7Y7u7upl8XAgICcOXKFQCATqcz/TcRkauobYlI3VyR5B52aGgosrOz0aFDB0RGRmLevHkoLCzEhg0b0LVrV3vESERkNSXd6Si5wl60aBFatmwJAHjrrbfg5+eHqVOnoqCgAGlpaTYPkIioMWrXEpG6uSLJFXbPnj1N/92iRQvs3LnTpgEREVH9eOMMESnaPb28anBw8F0b8j///HOjAiIisiUlzcOWnLDj4uLMXldVVSEnJwe7du3CrFmzbBUXEZFN3NMV9vTp0+vdv2rVKmRnZzc6ICIiW3LUAwz+/e9/Iz4+Hl9++SVu3ryJDh06YO3atQgLC5N8rgbjstWJoqKi8Nlnn9nqdERENlFbYUvdpPjtt9/wyCOPwN3dHV9++SXOnj2Lf/zjH7jvvvts+l1sNuj46aefwtfX11anIyKSjSVLlsBgMGDdunWmfW3atLH5day6ceaPDXlRFJGfn4/r169j9erVNg3OUjtffRRardYp1ybHavbwy84OgRxENFb++Ycs0JhBx5KSErP9Go0GGo2mzud37NiBv/71r3juueeQlZWFVq1aITY2FpMmTbI+8HpITthDhgwx+/IqlQotWrRAREQEOnbsaNPgiIgaSwXpvd/azxsMBrP9CQkJSExMrPP5n3/+GSkpKZgxYwbefPNNHDt2DK+++io0Gg1Gjx5tTdj1kpyw6wuWiMhVNabCzsvLM/vtvb7qGqh5KlfPnj2xaNEiADWdiDNnziAlJcWmCVvyoKNarUZBQUGd/UVFRVCr1TYJiojIVgQrVuqrze9ardZsayhht2zZEp06dTLbFxISYvMF8SRX2KIo1ru/oqICHh4ejQ6IiMiWHPFMx0ceeQQ//vij2b7z58+jdevW0k70JyxO2CtWrABQ86vCBx98gKZNm5reMxqNOHDgAHvYRHRPeu2119CnTx8sWrQIw4YNw7Fjx5CWlmbzBfEsTtjvvvsugJoKOzU11az94eHhgTZt2iA1NdWmwRERNZYjbk1/+OGHsW3bNsyePRsLFixAcHAwli9fjlGjRkk6z5+xOGHn5uYCACIjI7F161Y0a9bMpoEQEdmDI1oiAPDkk0/iySeflH6gBJJ72Pv27bNHHEREdqGktUQkzxJ59tlnsXjx4jr73377bTz33HM2CYqIyFaU9AADyQk7KysL0dHRdfY/8cQTOHDggE2CIiKyFZWVmyuSHFdZWVm90/fc3d3r3MZJRES2Izlhd+nSBVu2bKmzf/PmzXUmjhMROZsjVutzFMmDjnPnzsUzzzyDixcvon///gCAPXv2YOPGjfj0009tHiARUWOoYMV62C763HTJCfupp57C9u3bsWjRInz66afw8vJCt27dsHfvXq6YR0QuR0mzRKxaDzs6Oto08Pjf//4XH3/8MeLi4vDtt9/CaDTaNEAiosZw1DxsR7B6MHTv3r144YUXoNfrkZycjMGDB/MRYUTkcmoWf5I2pU8RFfYvv/yCjIwMpKeno7y8HMOGDUNVVRU+++wzDjgSEdmZxRX24MGD0alTJ5w9exYrV67E1atXsXLlSnvGRkTUaPfkLJHdu3fj1VdfxdSpU9G+fXt7xkREZDP3ZA/74MGDKC0tRc+ePdG7d28kJyfj+vXr9oyNiKjRBCv/uCKLE3Z4eDjWrFmDa9euYcqUKdi8eTNatWqF6upqZGZmorS01J5xEhFZRerTZqypyB1F8iyRJk2aYPz48Th06BBOnz6NmTNnYvHixfD398dTTz1ljxiJiKx2TyfsP3rwwQexdOlS/PLLL9i0aZOtYiIionpYdePMndRqNYYOHYqhQ4fa4nRERDbjiCfOOIpNEjYRkatS0iwRJmwiUrR7fi0RIiK5sOYJMq76xBkmbCJSNCW1RFz1SThERHQHVthEpGzWrA3iohU2EzYRKZoKguQnyCjmiTNERHLCWSJERDKhpEFHJmwiUjQlTevjLBEiIplghU1EisYeNhGRTKhgRUuEs0SIiByPFTYRkUyoIH2wzlUH95iwiUjRlLQetqv+ICEiojuwwiYiRRMgfWkQ16yvmbCJSOGUdOMMEzYRKZ5rpl/pmLCJSNE4rY+ISCY4S4SIiByOCZuIFE1l5WatpKQkCIKAuLi4RpylfmyJEJGiObIlcvz4caSlpeGhhx6y6vg/wwqbiBRNsHKTqqysDKNGjcKaNWvQrFkzW4ReBxM2ESlabYUtdQOAkpISs62ioqLB60ybNg3R0dEYOHCg3b4LEzYRKVpjetgGgwE6nc60JSUl1XuNzZs34+TJkw2+byvsYRMRNSAvLw9ardb0WqPR1PuZ6dOnY/fu3fD09LRrPEzYRKRojRl01Gq1Zgm7PidOnEBBQQHCwsJM+4xGIw4cOIDk5GRUVFRArVZLD7weTNhEpGj2XvxpwIABOH36tNm+cePGoWPHjoiPj7dZsgaYsIlI4ex9a7qPjw+6dOlits/b2xt+fn519jcWEzYRKZoKguRnNPKZjmQzagFQq2p+bRMBVBlr/pfk7ZEe7fDa6IHo0SkILVvoMOy1NHy+/zsAgJubComxMfjro50RfL8fSspuYe83P2Duih24dr3YyZG7Nmcs/rR///7GnaABTp3Wd+DAAcTExECv10MQBGzfvt2Z4ciCSgDcVICxGqg0AtUi4GG7Fhk5kbeXBqfP/xuvLf6kzntNPD3QPcSAxWu+RPiIJXh+5hq0D/LHP5dPcUKk5CxOrbDLy8vRrVs3jBs3Ds8884wzQ5ENNxVgFGs2ALhdDajUNftvVzs3Nmqc3V+fxe6vz9b7XknZLTw5Ndls34wl/8Shj1+HIbAZ8vJ/c0SIsiT8/kfqMa7IqQk7KioKUVFRzgxBdgTUVNV/VC3WVN50b9H6eKG6uhr/Lb3p7FBcGtfDdpKKigqzW0NLSkqcGI1zCAIg3pGwRRHKeaQGWUTj4Ya3Xh2CLV9mo7T8lrPDcWmCFYOOrlphy+rW9KSkJLPbRA0Gg7NDInI4NzcVNiweB5UgYHpS3X43mautsKVurkhWCXv27NkoLi42bXl5ec4OyeFEse7/mVz1/1xke25uKny8ZAJat/LDk1OTWV1bQEkJW1YtEY1GU++9/PcSETX96j/2se98TcpUm6zbBbXAE5NX4NficmeHRA4mq4RNNTNB3FWA+HuSrp2PzRki8uft5YF2hham121a+eGhDq3wW8kNXL1ejI1vT0RoRwOenp4KtUpAgJ8PAODX4huoum10Vtguj7NEbKSsrAwXLlwwvc7NzcWpU6fg6+uLoKAgJ0bmuqrFmuTs9nszS0TNfGySvx6dWmP3B9NNr5f+rWaq64YdR/H/p+5ETETNU0yObZltdtygie/h4ImfHBeozKgE6bOoXHXWlVMTdnZ2NiIjI02vZ8yYAQAYM2YMMjIynBSV6zOKgJFJWnEOnvgJXqEvN/j+3d6jhrHCtpGIiAiId85RIyKyISXNw5bVLBEionsZBx2JSNFq1sOW2hJxTUzYRKRoHHQkIpIJDjoSEcmEkgYdmbCJSNHs/UxHR+IsESIimWCFTUSKpoIAlcQeB5/pSETkBEpqiTBhE5GyKShjM2ETkaJxWh8RkVxY80AC18zXnCVCRCQXrLCJSNEU1MJmwiYihVNQxmbCJiJF46AjEZFMcC0RIiKZUFBHhLNEiIjkghU2ESmbgkpsJmwiUjQOOhIRyQQHHYmIZEJBHREmbCJSOAVlbM4SISKSCVbYRKRoHHQkIpIJDjoSEcmEglrYTNhEpHAKythM2ESkaErqYXOWCBFRIyUlJeHhhx+Gj48P/P39MXToUPz44482vw4TNhEpWu2go9RNiqysLEybNg1Hjx5FZmYmbt++jUGDBqG8vNym34UtESJStMa0sEtKSsz2azQaaDSaOp/ftWuX2et169bB398fJ06cwGOPPSbx6g1jhU1EyiZYuQEwGAzQ6XSmLSkpyaJLFhcXAwB8fX1t+EVYYRORwjVm0DEvLw9arda0v77q+k6iKGLGjBl49NFH0aVLF2nB/gkmbCJStMbcOKPVas0StiVefvllfPfddzh06JC0i1qACZuIyEZeeeUV7NixAwcOHMD9999v8/MzYRORojnivhlRFPHKK69g27Zt2L9/P4KDgyWewTJM2ESkbA7I2NOmTcPGjRvxP//zP/Dx8UF+fj4AQKfTwcvLS+LFG8ZZIkSkaIKVf6RISUlBcXExIiIi0LJlS9O2ZcsWm34XVthEpGxWDDpKrbBFUZR4AeswYRORoilo7Se2RIiI5IIVNhEpm4JKbCZsIlI0JS2vyoRNRIrGR4QREcmEgjoiTNhEpHAKyticJUJEJBOssIlI0TjoSEQkEwKsGHS0SySNx4RNRIqmoBY2EzYRKRun9RERyYZyamxZJ+zaFbJK73iyMSmXaKx0dgjkILX/1o5aCU8OZJ2wS0tLAQAPBBucHAkR2UtpaSl0Op3Vx7Ml4iL0ej3y8vLg4+MDwVX/hu2gpKQEBoOhzhOdSZnu1X9vURRRWloKvV7fqPMopyEi84StUqns8qBLubDmic4kX/fiv3djKutarLCJiGSCN84QEcmFgnoiXEtEhjQaDRISEqDRaJwdCjkA/72pliByzgwRKVBJSQl0Oh1+yiuEj8Tef2lJCdobmqO4uNilxg3YEiEiReOgIxGRTHDQkYhILhQ06MiETUSKpqB8zVkicrR69WoEBwfD09MTYWFhOHjwoLNDIjs4cOAAYmJioNfrIQgCtm/f7uyQyMmYsGVmy5YtiIuLw5w5c5CTk4O+ffsiKioKV65ccXZoZGPl5eXo1q0bkpOTnR2KrNUOOkrdXBGn9clM79690aNHD6SkpJj2hYSEYOjQoUhKSnJiZGRPgiBg27ZtGDp0qLNDkY3aaX25V3+VPDWvpKQEwXpfl5vWxwpbRiorK3HixAkMGjTIbP+gQYNw+PBhJ0VF5NqUVGEzYctIYWEhjEYjAgICzPYHBAQgPz/fSVERkaNwlogM3bmUrCiK99TyskRSKOnGGVbYMtK8eXOo1eo61XRBQUGdqpuIlIcJW0Y8PDwQFhaGzMxMs/2ZmZno06ePk6Iicm2ClX9cEVsiMjNjxgy8+OKL6NmzJ8LDw5GWloYrV67gpZdecnZoZGNlZWW4cOGC6XVubi5OnToFX19fBAUFOTEyeVFSS4QJW2aGDx+OoqIiLFiwANeuXUOXLl2wc+dOtG7d2tmhkY1lZ2cjMjLS9HrGjBkAgDFjxiAjI8NJUcmPku505DxsIlKk2nnYvxT8ZtU87Pv9m3EeNhERWYctESJSNC6vSkQkExx0JCKSCSUNOrKHTUTKJli5WcHeSx8zYRORojnqxhlHLH3MaX1EpEi10/ryC6VPzSspKUFgc52kaX2OWPqYPWwiUrTS0hLJg4ilpSUAahL3H2k0Gmg0mjqfr136+I033jDbb+ulj9kSIZeVmJiI7t27m16PHTvWKQv4X7p0CYIg4NSpUw6/NlnPw8MDgYGBaB9sQICfTtLWPtiApk2bwmAwQKfTmbaGKmVHLX3MCpskGzt2LNavXw8AcHNzg8FgwNNPP4358+fD29vbbtd97733YGkH79KlSwgODkZOTo5Z0qd7h6enJ3Jzc1FZWWnV8fUtW1xfdf1H9l76mAmbrPLEE09g3bp1qKqqwsGDBzFx4kSUl5eb9e8AoKqqCu7u7ja5pk6ns8l56N7h6ekJT09Pu1/HUUsfsyVCVtFoNAgMDITBYMDIkSMxatQobN++3dTGSE9PR9u2baHRaCCKIoqLizF58mT4+/tDq9Wif//++Pbbb83OuXjxYgQEBMDHxwcTJkzArVu3zN6/syVSXV2NJUuW4IEHHoBGo0FQUBAWLlwIAAgODgYAhIaGQhAEREREmI5bt24dQkJC4OnpiY4dO2L16tVm1zl27BhCQ0Ph6emJnj17Iicnx4Z/c6REjlr6mBU22YSXlxeqqqoAABcuXMAnn3yCzz77DGq1GgAQHR0NX19f7Ny5EzqdDu+//z4GDBiA8+fPw9fXF5988gkSEhKwatUq9O3bFxs2bMCKFSvQtm3bBq85e/ZsrFmzBu+++y4effRRXLt2DT/88AOAmqTbq1cvfPXVV+jcuTM8PDwAAGvWrEFCQgKSk5MRGhqKnJwcTJo0Cd7e3hgzZgzKy8vx5JNPon///vjoo4+Qm5uL6dOn2/lvj5TAIUsfi0QSjRkzRhwyZIjp9TfffCP6+fmJw4YNExMSEkR3d3exoKDA9P6ePXtErVYr3rp1y+w87dq1E99//31RFEUxPDxcfOmll8ze7927t9itW7d6r1tSUiJqNBpxzZo19caYm5srAhBzcnLM9hsMBnHjxo1m+9566y0xPDxcFEVRfP/990VfX1+xvLzc9H5KSkq95yK606pVq8TWrVuLHh4eYo8ePcSsrCybnp8VNlnliy++QNOmTXH79m1UVVVhyJAhWLlyJVavXo3WrVujRYsWps+eOHECZWVl8PPzMzvHzZs3cfHiRQDAuXPn6lQi4eHh2LdvX73XP3fuHCoqKjBgwACLY75+/Try8vIwYcIETJo0ybT/9u3bpv74uXPn0K1bNzRp0sQsDiJLxMbGIjY21m7nZ8Imq0RGRiIlJQXu7u7Q6/VmA4t3zhSprq5Gy5YtsX///jrnue+++6y6vpeXl+RjqqurAdS0RXr37m32Xm3rRuR9ZOTCmLDJKt7e3njggQcs+myPHj2Qn58PNzc3tGnTpt7PhISE4OjRoxg9erRp39GjRxs8Z/v27eHl5YU9e/Zg4sSJdd6v7VkbjUbTvoCAALRq1Qo///wzRo0aVe95O3XqhA0bNuDmzZumHwp3i4PIkThLhOxu4MCBCA8Px9ChQ/G///u/uHTpEg4fPoy///3vyM7OBgBMnz4d6enpSE9Px/nz55GQkIAzZ840eE5PT0/Ex8fj9ddfx4cffoiLFy/i6NGjWLt2LQDA398fXl5e2LVrF/7zn/+guLgYQM3NOElJSXjvvfdw/vx5nD59GuvWrcOyZcsAACNHjoRKpcKECRNw9uxZ7Ny5E++8846d/4aILMOETXYnCAJ27tyJxx57DOPHj0eHDh3w/PPP49KlS6Y5qsOHD8e8efMQHx+PsLAwXL58GVOnTr3reefOnYuZM2di3rx5CAkJwfDhw1FQUACg5oaeFStW4P3334der8eQIUMAABMnTsQHH3yAjIwMdO3aFf369UNGRoZpGmDTpk3x+eef4+zZswgNDcWcOXOwZMkSO/7tEFmOiz8REckEK2wiIplgwiYikgkmbCIimWDCJiKSCSZsIiKZYMImIpIJJmwiIplgwiYikgkmbCIimWDCJiKSCSZsIiKZ+H9510dnDw2ndAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix'); plt.colorbar()\n",
    "plt.xticks([0,1]); plt.yticks([0,1])\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, cm[i,j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09468160-cdfb-4212-a79d-05a9912c5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision:\", p)\n",
    "print(\"Recall:\", r)\n",
    "print(\"F1 Score:\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9a3eafa0-a616-4bfb-bf2d-780fd41134fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced + class_weight Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance\n",
    "y_imbal = np.hstack((np.zeros(len(y)-10), np.ones(10)))\n",
    "X_imbal = x[:len(y_imbal)]\n",
    "lr_w = LogisticRegression(class_weight='balanced', max_iter=500).fit(X_imbal, y_imbal)\n",
    "print(\"Imbalanced + class_weight Accuracy:\", accuracy_score(y_imbal, lr_w.predict(X_imbal)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "616c2b2a-0ff7-4de5-bd61-23488ed57755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Logistic Regression Accuracy: 0.7713004484304933\n"
     ]
    }
   ],
   "source": [
    "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Drop non-numeric or irrelevant columns\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Titanic Logistic Regression Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "846652c0-a3fc-4751-ae4a-54802ad5965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without scaling: 1.0\n",
      "With scaling: 1.0\n"
     ]
    }
   ],
   "source": [
    "#15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train, x_test = scaler.transform(x_train), scaler.transform(x_test)\n",
    "acc_no = accuracy_score(y_test, LogisticRegression(max_iter=500).fit(x_train, y_train).predict(x_test))\n",
    "acc_yes = accuracy_score(y_test, LogisticRegression(max_iter=500).fit(x_train, y_train).predict(x_test))\n",
    "print(\"without scaling:\", acc_no)\n",
    "print(\"With scaling:\", acc_yes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "db7e90c6-1aea-47f9-9283-c6430b622a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
    "from sklearn.metrics import roc_curve , auc\n",
    "\n",
    "y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr , tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0da97653-8f97-40af-9e2b-1f68661b3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\n",
    "model_custom = LogisticRegression(C=0.5, max_iter=500)\n",
    "model_custom.fit(x_train,y_train)\n",
    "print(\"Accuracy Score :\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f5214d0f-a01a-4785-adc3-a5b268518717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features:\n",
      " petal length (cm)    2.131055\n",
      "petal width (cm)     0.969290\n",
      "sepal length (cm)   -0.407355\n",
      "sepal width (cm)    -1.379103\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
    "coefs = pd.Series(model_l2.coef_[0], index=data.feature_names)\n",
    "print(\"Top features:\\n\",coefs.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5d5445ac-303a-4a0a-acbf-c4e9da85b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa: 1.0\n"
     ]
    }
   ],
   "source": [
    "#19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(\"Cohen Kappa:\", cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f514b624-4f54-4de6-a36c-6df2a7e6cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classificatio\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4300d76e-2598-4e8d-8732-0b34b7a7c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver liblinear acc :  1.0\n",
      "solver saga acc :  1.0\n",
      "solver lbfgs acc :  1.0\n"
     ]
    }
   ],
   "source": [
    "#21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n",
    "for sol in [\"liblinear\", \"saga\", \"lbfgs\"]:\n",
    "    model_solver = LogisticRegression(solver=sol , max_iter=500)\n",
    "    model_solver.fit(x_train,y_train)\n",
    "    y_pred_sol = model_solver.predict(x_test)\n",
    "    print(f\"solver {sol} acc : \" , accuracy_score(y_test,y_pred_sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fd324313-2936-4525-9dec-833a6fdf6641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "#22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "790c17c3-955f-4b27-ad3f-d887fdd76bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without scaling: 1.0\n",
      "With scaling: 1.0\n"
     ]
    }
   ],
   "source": [
    "#23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train, x_test = scaler.transform(x_train), scaler.transform(x_test)\n",
    "acc_no = accuracy_score(y_test, LogisticRegression(max_iter=500).fit(x_train, y_train).predict(x_test))\n",
    "acc_yes = accuracy_score(y_test,LogisticRegression(max_iter=500).fit(x_train, y_train).predict(x_test))\n",
    "print(\"without scaling:\", acc_no)\n",
    "print(\"With scaling:\", acc_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2d5250d4-a2fd-4698-b634-4fb3921ea548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=1, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=2, penalty=l2; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ............................C=2, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=10, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=20, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=20, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=30, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=30, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=40, penalty=l2; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ...........................C=40, penalty=elasticnet; total time=   0.0s\n",
      "Gridsearchcv Best : {'C': 1, 'penalty': 'l2'}\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\"penalty\": (\"l1\", \"l2\", \"elasticnet\"), 'C': [1, 2, 10, 20, 30, 40]}\n",
    "classifier = LogisticRegression()\n",
    "clf = GridSearchCV(classifier , param_grid= params , cv=5 ,verbose=2)\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Gridsearchcv Best :\" ,clf.best_params_)\n",
    "print(\"Accuracy :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7ed060f1-dc6e-4e63-a5ce-1b9d82f0e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
    "import joblib\n",
    "joblib.dump(model_l2, 'lr_model.pkl')\n",
    "lr_loaded = joblib.load('lr_model.pkl')\n",
    "print(\"Loaded model accuracy:\", accuracy_score(y_test, lr_loaded.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582ee29-195e-49fd-bbba-1f68e6467fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbe1fa-04a6-4b17-bd76-bbcbdf2ebf69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1930cc0-db52-41b6-8a7a-d1bcc8dc4f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7eb83-d8c7-4d41-a548-1bac5e046c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d600ee9-1e81-4bf6-88cc-9ca79f34b816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04aa10-11d3-430e-b79e-908689b17ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c6c8e-1bcf-4a75-ac63-d1af4eb518c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125becf-b112-4af4-942b-070af5eb1812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27875ce5-b466-4d70-8b86-3aca50128895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc6bb2-2f04-48b6-8696-a99c3a402fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07742480-7e8c-4c7e-98de-f4070894fa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c67327-6ed5-4e96-bc95-9d998f809ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc501c50-92d8-41fd-9b05-fcdd72182dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e970ae-c579-4ec7-989c-faaf8d577d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598edc1-0b2f-481b-aa00-1f9ce8467700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15d9c5-b142-4b01-8250-fdf9202fd74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
